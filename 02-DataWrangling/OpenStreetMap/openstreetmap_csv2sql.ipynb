{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from CSV files to SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sqlite3, time, pandas, csv\n",
    "project_path = \"C:\\\\Users\\\\TO72078\\\\Documents\\\\BIG_DATA\\\\UDACITY\\\\projects\\\\openstreetmap\"\n",
    "db_name = 'toulouse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import our SQLite helper functions (empty_db, create_tables, list_tables, display_schema, db_query...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(project_path)\n",
    "import myeasysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite database preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a database (or connect to an existing one and empty it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping table nodes\n",
      "dropping table node_tags\n",
      "dropping table ways\n",
      "dropping table way_tags\n",
      "dropping table way_nodes\n",
      "Freeing memory on disk\n"
     ]
    }
   ],
   "source": [
    "db_conn = sqlite3.connect(os.path.join(project_path, '%s.db' % db_name))\n",
    "db_conn.text_factory = str # by default sqlite3 uses unicode, raises error while inserting data with pandas.to_sql()\n",
    "myeasysql.empty_db(db_conn) # for testing purpose, the database may be already filled with test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the openstreetmap clean data tables and check their scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CREATE TABLE nodes\\n    (\\n        id INTEGER PRIMARY KEY,\\n        lat REAL,\\n        lon REAL,\\n        user TEXT,\\n        uid INTEGER,\\n        version TEXT,\\n        changeset INTEGER,\\n        timestamp TEXT,\\n        FOREIGN KEY (uid)  REFERENCES ways (uid),\\n        FOREIGN KEY (user) REFERENCES ways (user)\\n    )',),\n",
       " ('CREATE TABLE node_tags\\n    (\\n        id INTEGER,\\n        key TEXT,\\n        value TEXT,\\n        type TEXT,\\n        valid TEXT,\\n        FOREIGN KEY (id) REFERENCES nodes (id)\\n    )',),\n",
       " ('CREATE TABLE ways\\n    (\\n        id INTEGER PRIMARY KEY,\\n        user TEXT,\\n        uid INTEGER,\\n        version TEXT,\\n        changeset INTEGER,\\n        timestamp TEXT,\\n        FOREIGN KEY (uid)  REFERENCES nodes (uid),\\n        FOREIGN KEY (user) REFERENCES nodes (user)\\n    )',),\n",
       " ('CREATE TABLE way_tags\\n    (\\n        id INTEGER,\\n        key TEXT,\\n        value TEXT,\\n        type TEXT,\\n        valid TEXT,\\n        FOREIGN KEY (id) REFERENCES way (id)\\n    )',),\n",
       " ('CREATE TABLE way_nodes\\n    (\\n        id INTEGER,\\n        node_id INTEGER PRIMARY KEY,\\n        position INTEGER,\\n        FOREIGN KEY (id)  REFERENCES ways (id),\\n        FOREIGN KEY (node_id) REFERENCES nodes (id)\\n    )',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = db_conn.cursor()\n",
    "myeasysql.create_tables(c)\n",
    "myeasysql.list_tables(c)\n",
    "myeasysql.display_schema(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy coding with Pandas one-liners\n",
    "Now for every table, let's let pandas module read the CSV data and insert it into our database. We call it \"lazy coding\" since pandas offers one-line features for both actions. Let's check memory and CPU of the whole procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### nodes ######\n",
      "       id        lat       lon            user      uid  version  changeset  \\\n",
      "0  625219  43.549540  1.471045  Quentin SALLES  6604122        3   53577892   \n",
      "1  625226  43.552357  1.478125           Yod4z   318821        9   36224374   \n",
      "2  625235  43.554292  1.471321         hromain    39569        2     750508   \n",
      "3  625236  43.555496  1.472247         hromain    39569        2     750508   \n",
      "4  625239  43.554530  1.470092   Florian Birée    26867        4    4785749   \n",
      "\n",
      "              timestamp  \n",
      "0  2017-11-07T10:35:43Z  \n",
      "1  2015-12-28T17:05:52Z  \n",
      "2  2009-03-07T17:58:17Z  \n",
      "3  2009-03-07T17:58:17Z  \n",
      "4  2010-05-23T17:59:11Z  \n",
      "###### node_tags ######\n",
      "       id               key          value     type valid\n",
      "0  625219               bus            yes  regular   yes\n",
      "1  625219           highway       bus_stop  regular   yes\n",
      "2  625219              name      Lapeyrade  regular   yes\n",
      "3  625219          operator         Tisséo  regular   yes\n",
      "4  625219  public_transport  stop_position  regular   yes\n",
      "###### ways ######\n",
      "        id            user      uid  version  changeset             timestamp\n",
      "0  1863458       Hervé TUC   922338        9   51336738  2017-08-22T11:09:10Z\n",
      "1  2304962          Soiouz  5744795       18   48508488  2017-05-08T17:47:35Z\n",
      "2  2304963     Hugo Bayles    94997        9   13351965  2012-10-03T19:50:53Z\n",
      "3  2305016          Soiouz  5744795       19   48508488  2017-05-08T17:44:48Z\n",
      "4  2305119  Quentin SALLES  6604122       24   54201835  2017-11-30T11:02:35Z\n",
      "###### way_nodes ######\n",
      "        id     node_id  position\n",
      "0  1863458     8010736         0\n",
      "1  1863458  4840560425         1\n",
      "2  1863458     8010738         2\n",
      "3  1863458  4840560424         3\n",
      "4  1863458  4840560423         4\n",
      "###### way_tags ######\n",
      "        id      key                       value     type valid\n",
      "0  1863458  highway                 residential  regular   yes\n",
      "1  1863458     name                   Rue Julia  regular   yes\n",
      "2  1863458   oneway                          no  regular   yes\n",
      "3  1863458  surface                     asphalt  regular   yes\n",
      "4  2304962     name  Pont de la Croix de Pierre  regular   yes\n",
      "elapsed time = 33.7269999981\n"
     ]
    }
   ],
   "source": [
    "# before: 50Mb (python core + imported modules)\n",
    "\n",
    "start_time = time.time()\n",
    "for table_name in ('nodes', 'node_tags', 'ways', 'way_nodes', 'way_tags'):\n",
    "    csv_file = os.path.join(project_path, \"%s_%s.csv\" % (db_name, table_name))\n",
    "    df = pandas.read_csv(csv_file)\n",
    "    print '###### %s ######' % table_name\n",
    "    print df.head()\n",
    "    df.to_sql(table_name, db_conn, if_exists='replace', index=False)\n",
    "    # mem peak ~1Gb\n",
    "    # after: 500Mb\n",
    "end_time = time.time()\n",
    "print 'elapsed time = %s' % (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First observation: big amount of memory consumption occurs since panda.read_csv returns a dataframe stored in-memory. this statement could raise some blocking issue with bigger OSM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nodes', 'node_tags', 'ways', 'way_nodes', 'way_tags']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('CREATE TABLE \"nodes\" (\\n\"id\" INTEGER,\\n  \"lat\" REAL,\\n  \"lon\" REAL,\\n  \"user\" TEXT,\\n  \"uid\" INTEGER,\\n  \"version\" INTEGER,\\n  \"changeset\" INTEGER,\\n  \"timestamp\" TEXT\\n)',),\n",
       " ('CREATE TABLE \"node_tags\" (\\n\"id\" INTEGER,\\n  \"key\" TEXT,\\n  \"value\" TEXT,\\n  \"type\" TEXT,\\n  \"valid\" TEXT\\n)',),\n",
       " ('CREATE TABLE \"ways\" (\\n\"id\" INTEGER,\\n  \"user\" TEXT,\\n  \"uid\" INTEGER,\\n  \"version\" INTEGER,\\n  \"changeset\" INTEGER,\\n  \"timestamp\" TEXT\\n)',),\n",
       " ('CREATE TABLE \"way_nodes\" (\\n\"id\" INTEGER,\\n  \"node_id\" INTEGER,\\n  \"position\" INTEGER\\n)',),\n",
       " ('CREATE TABLE \"way_tags\" (\\n\"id\" INTEGER,\\n  \"key\" TEXT,\\n  \"value\" TEXT,\\n  \"type\" TEXT,\\n  \"valid\" TEXT\\n)',)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print myeasysql.list_tables(c)\n",
    "myeasysql.display_schema(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second observation: the table scheme have been broken and partially rebuilt by Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's close the link with the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after closing the link, memory has not been freed, let's collect the garbage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before 500Mb\n",
    "import gc\n",
    "gc.collect()\n",
    "# after 100Mb\n",
    "del df\n",
    "gc.collect()\n",
    "# after 50Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy CSV reading and row-by-row SQL inserting\n",
    "Now let's try another strategy, by coding some CSV reading based on generators to preserve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn = sqlite3.connect(os.path.join(project_path, '%s.db' % db_name))\n",
    "db_conn.text_factory = str\n",
    "db_cursor = db_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping table nodes\n",
      "dropping table node_tags\n",
      "dropping table ways\n",
      "dropping table way_tags\n",
      "dropping table way_nodes\n",
      "Freeing memory on disk\n"
     ]
    }
   ],
   "source": [
    "myeasysql.empty_db(db_cursor)\n",
    "db_conn.commit() # in case db is locked following a crash during previous transactions\n",
    "myeasysql.create_tables(db_cursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lazy loadind requires more effort in terms of coding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lazyread_csv_data(csv_path):\n",
    "    \"\"\"build a CSV row generator\"\"\"\n",
    "    with open(csv_path, 'rU') as data:\n",
    "        reader = csv.DictReader(data)\n",
    "        for row in reader:\n",
    "            # yealding instead of returning avoids in-memory work\n",
    "            yield {k: str_encode(v) for k, v in row.iteritems()}\n",
    "                \n",
    "def str_encode(v):\n",
    "    \"\"\"Return string object properly encoded if necessary\"\"\"\n",
    "    return v.encode('utf-8') if isinstance(v, unicode) else str(v)\n",
    "\n",
    "\n",
    "def insert_data(db_conn, table_name, csv_path):\n",
    "    \"\"\"Insert csv data into SQL\"\"\"\n",
    "    from sqlite3 import OperationalError\n",
    "    db_cursor = db_conn.cursor()\n",
    "    generator = lazyread_csv_data(csv_path)\n",
    "    try:\n",
    "        for i, row in enumerate(generator):\n",
    "            QUERY=\"INSERT INTO %s (%s) VALUES (%s)\" % (table_name, ','.join(row.keys()), ','.join(['?' for k in row.keys()]))\n",
    "            db_cursor.execute(QUERY, row.values())\n",
    "    except OperationalError as e:\n",
    "        print 'Failed while inserting:'\n",
    "        print QUERY\n",
    "        print 'sqlite error:', e\n",
    "        return None\n",
    "    finally:\n",
    "        db_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply previous functions to the 5 tables required by our project. Again, memory and CPU are checked or monitored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating nodes\n",
      "Populating node_tags\n",
      "Populating ways\n",
      "Populating way_nodes\n",
      "Populating way_tags\n",
      "elapsed time = 93.3800001144\n"
     ]
    }
   ],
   "source": [
    "# before: 50Mb (python core + imported modules)\n",
    "# mem peak ~50Mb\n",
    "start_time = time.time()\n",
    "for table_name in ('nodes', 'node_tags', 'ways', 'way_nodes', 'way_tags'):\n",
    "    print 'Populating %s' % table_name\n",
    "    csv_file = os.path.join(project_path, \"%s_%s.csv\" % (db_name, table_name))\n",
    "    insert_data(db_conn, table_name, csv_file)\n",
    "# after: 50Mb\n",
    "end_time = time.time()\n",
    "print 'elapsed time = %s' % (end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: CSV lazy reading instead of pandas read_csv allows to avoid any memory consumption. The cost of this strategie is a CPU factor 3. This strategy is preferred since preserving the table scheme and handling even big OSM data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish, let's close the database connector and switch to another notebook dedicated to database checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
